#!/usr/bin/env python3
"""
è¶…æ™ºèƒ½å­—å¹•ç¿»è¯‘å™¨
- æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- æ™ºèƒ½åˆ†æ®µï¼ˆåœ¨è‡ªç„¶æ–­ç‚¹å¤„åˆ†æ‰¹ï¼‰
- åŠ¨æ€æ‰¹æ¬¡å¤§å°
- ä¿æŒä¸Šä¸‹æ–‡è¿è´¯
- æ”¯æŒ VTT å’Œ SRT æ ¼å¼
"""

import os
import re
import json
import argparse
from pathlib import Path
from openai import OpenAI
import logging
from datetime import datetime
from subtitle_parser import parse_subtitle, write_subtitle, detect_format

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class SuperSmartVTTTranslator:
    """è¶…æ™ºèƒ½å­—å¹•ç¿»è¯‘å™¨"""
    
    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        
        if not self.api_key:
            raise ValueError("è¯·æä¾› DeepSeek API Key æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com"
        )
    
    def parse_vtt(self, vtt_path: str) -> list:
        """è§£æ VTT å­—å¹•æ–‡ä»¶"""
        logger.info(f"ğŸ“– è¯»å–å­—å¹•æ–‡ä»¶: {vtt_path}")
        
        with open(vtt_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        blocks = []
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if not line or line.startswith('WEBVTT') or line.startswith('Kind:') or line.startswith('Language:'):
                i += 1
                continue
            
            if '-->' in line:
                timestamp = line
                text_lines = []
                i += 1
                
                while i < len(lines) and lines[i].strip() and '-->' not in lines[i]:
                    text_line = lines[i].strip()
                    text_line = re.sub(r'&nbsp;', ' ', text_line)
                    text_line = re.sub(r'<[^>]+>', '', text_line)
                    if text_line:
                        text_lines.append(text_line)
                    i += 1
                
                if text_lines:
                    blocks.append({
                        'timestamp': timestamp,
                        'text': ' '.join(text_lines),
                        'translated': None
                    })
            else:
                i += 1
        
        logger.info(f"âœ… è§£æå®Œæˆï¼Œå…± {len(blocks)} ä¸ªå­—å¹•å—")
        return blocks
    
    def is_natural_breakpoint(self, text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯è‡ªç„¶æ–­ç‚¹
        
        Args:
            text: å­—å¹•æ–‡æœ¬
            
        Returns:
            æ˜¯å¦æ˜¯è‡ªç„¶æ–­ç‚¹
        """
        # æ£€æŸ¥æ˜¯å¦ä»¥å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€çœç•¥å·ç­‰ç»“æŸ
        sentence_endings = ['.', '!', '?', '...', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'â€¦']
        
        text = text.strip()
        for ending in sentence_endings:
            if text.endswith(ending):
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹è¯ç»“æŸï¼ˆå¼•å·åçš„æ ‡ç‚¹ï¼‰
        if text.endswith('."') or text.endswith('!"') or text.endswith('?"'):
            return True
        
        return False
    
    def create_smart_batches(
        self,
        blocks: list,
        target_size: int = 50,
        min_size: int = 30,
        max_size: int = 70
    ) -> list:
        """
        æ™ºèƒ½åˆ›å»ºæ‰¹æ¬¡ï¼ˆåœ¨è‡ªç„¶æ–­ç‚¹å¤„åˆ†æ‰¹ï¼‰
        
        Args:
            blocks: å­—å¹•å—åˆ—è¡¨
            target_size: ç›®æ ‡æ‰¹æ¬¡å¤§å°
            min_size: æœ€å°æ‰¹æ¬¡å¤§å°
            max_size: æœ€å¤§æ‰¹æ¬¡å¤§å°
            
        Returns:
            æ‰¹æ¬¡åˆ—è¡¨ï¼Œæ¯ä¸ªæ‰¹æ¬¡æ˜¯å­—å¹•å—çš„ç´¢å¼•èŒƒå›´ [(start, end), ...]
        """
        logger.info(f"ğŸ§  æ™ºèƒ½åˆ†æ‰¹...")
        logger.info(f"   ç›®æ ‡æ‰¹æ¬¡å¤§å°: {target_size}")
        logger.info(f"   å…è®¸èŒƒå›´: {min_size}-{max_size}")
        
        batches = []
        start_idx = 0
        current_size = 0
        
        for i, block in enumerate(blocks):
            current_size += 1
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å¤§å°é™„è¿‘
            if current_size >= min_size:
                # å¦‚æœæ˜¯è‡ªç„¶æ–­ç‚¹ï¼Œæˆ–è€…è¾¾åˆ°æœ€å¤§å¤§å°
                if self.is_natural_breakpoint(block['text']) or current_size >= max_size:
                    batches.append((start_idx, i + 1))
                    logger.debug(f"   æ‰¹æ¬¡ {len(batches)}: [{start_idx}, {i+1}), å¤§å°: {current_size}")
                    start_idx = i + 1
                    current_size = 0
        
        # å¤„ç†å‰©ä½™çš„
        if start_idx < len(blocks):
            batches.append((start_idx, len(blocks)))
            logger.debug(f"   æ‰¹æ¬¡ {len(batches)}: [{start_idx}, {len(blocks)}), å¤§å°: {len(blocks) - start_idx}")
        
        logger.info(f"âœ… åˆ†æ‰¹å®Œæˆï¼Œå…± {len(batches)} ä¸ªæ‰¹æ¬¡")
        
        # ç»Ÿè®¡æ‰¹æ¬¡å¤§å°
        sizes = [end - start for start, end in batches]
        avg_size = sum(sizes) / len(sizes) if sizes else 0
        logger.info(f"   å¹³å‡æ‰¹æ¬¡å¤§å°: {avg_size:.1f}")
        logger.info(f"   æœ€å°æ‰¹æ¬¡: {min(sizes) if sizes else 0}")
        logger.info(f"   æœ€å¤§æ‰¹æ¬¡: {max(sizes) if sizes else 0}")
        
        return batches
    
    def save_progress(self, progress_file: str, blocks: list, current_batch: int, batches: list):
        """ä¿å­˜ç¿»è¯‘è¿›åº¦"""
        progress_data = {
            'timestamp': datetime.now().isoformat(),
            'current_batch': current_batch,
            'total_blocks': len(blocks),
            'batches': batches,
            'blocks': blocks
        }
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {progress_file}")
    
    def load_progress(self, progress_file: str) -> tuple:
        """åŠ è½½ç¿»è¯‘è¿›åº¦"""
        if not os.path.exists(progress_file):
            return None, 0, None
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            blocks = progress_data['blocks']
            current_batch = progress_data['current_batch']
            batches = progress_data.get('batches')
            
            logger.info(f"ğŸ“‚ æ‰¾åˆ°è¿›åº¦æ–‡ä»¶ï¼Œä¸Šæ¬¡ç¿»è¯‘åˆ°æ‰¹æ¬¡ {current_batch}")
            logger.info(f"   æ—¶é—´: {progress_data['timestamp']}")
            
            translated_count = sum(1 for b in blocks if b.get('translated'))
            logger.info(f"   å·²ç¿»è¯‘: {translated_count}/{len(blocks)} æ¡")
            
            return blocks, current_batch, batches
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
            return None, 0, None
    
    def translate_batch(self, texts: list, retry_count: int = 0, max_retries: int = 3) -> list:
        """ç¿»è¯‘ä¸€æ‰¹æ–‡æœ¬ï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
        text_dict = {str(idx): text for idx, text in enumerate(texts)}
        
        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡å­—å¹•ç¿»è¯‘æˆä¸­æ–‡ã€‚è¦æ±‚ï¼š
1. ä¿æŒåŸæ„ï¼Œè¯‘æ–‡è‡ªç„¶æµç•…
2. æ³¨æ„ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼Œè¿™äº›å­—å¹•æ˜¯è¿ç»­çš„
3. é€‚åˆå­—å¹•æ˜¾ç¤ºï¼Œç®€æ´æ˜“è¯»
4. ä¸“ä¸šæœ¯è¯­å‡†ç¡®ç¿»è¯‘
5. è¿”å›çº¯ JSON æ ¼å¼ï¼Œkey æ˜¯åºå·ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œvalue æ˜¯ç¿»è¯‘åçš„æ–‡æœ¬
6. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°ï¼Œåªè¿”å› JSON å¯¹è±¡

åŸæ–‡ï¼ˆå…± {len(texts)} æ¡è¿ç»­å­—å¹•ï¼‰ï¼š
{json.dumps(text_dict, ensure_ascii=False, indent=2)}

è¯·ç›´æ¥è¿”å›æ ‡å‡† JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ï¼š{{"0": "ç¿»è¯‘æ–‡æœ¬", "1": "ç¿»è¯‘æ–‡æœ¬", ...}}"""

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å­—å¹•ç¿»è¯‘ä¸“å®¶ã€‚åªè¿”å›æ ‡å‡† JSON æ ¼å¼çš„ç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹æˆ–æ ‡è®°ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000
            )
            
            content = response.choices[0].message.content.strip()
            
            # å¤šç§æ–¹å¼æå– JSON
            json_content = self.extract_json(content)
            
            if not json_content:
                logger.warning(f"âš ï¸  æ— æ³•æå– JSONï¼ŒåŸå§‹å“åº”å‰200å­—ç¬¦ï¼š\n{content[:200]}")
                raise ValueError("æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„ JSON")
            
            translated_dict = json.loads(json_content)
            
            # æŒ‰é¡ºåºæå–ç¿»è¯‘ç»“æœ
            translations = []
            for idx in range(len(texts)):
                translation = translated_dict.get(str(idx), texts[idx])
                translations.append(translation)
            
            # æ£€æµ‹ç¿»è¯‘æ˜¯å¦çœŸçš„æˆåŠŸï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡å­—ç¬¦ï¼‰
            chinese_count = sum(1 for t in translations if self.has_chinese(t))
            if chinese_count < len(translations) * 0.5:  # å¦‚æœè¶…è¿‡50%æ²¡æœ‰ä¸­æ–‡ï¼Œè®¤ä¸ºç¿»è¯‘å¤±è´¥
                logger.warning(f"âš ï¸  ç¿»è¯‘ç»“æœæ£€æµ‹ï¼šåªæœ‰ {chinese_count}/{len(translations)} æ¡åŒ…å«ä¸­æ–‡")
                raise ValueError("ç¿»è¯‘ç»“æœä¸åŒ…å«è¶³å¤Ÿçš„ä¸­æ–‡å†…å®¹ï¼Œå¯èƒ½ç¿»è¯‘å¤±è´¥")
            
            return translations
            
        except json.JSONDecodeError as e:
            if retry_count < max_retries:
                logger.warning(f"âš ï¸  JSON è§£æå¤±è´¥ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰ï¼Œé‡è¯•ä¸­...")
                import time
                time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                return self.translate_batch(texts, retry_count + 1, max_retries)
            else:
                logger.error(f"âŒ JSON è§£æå¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {e}")
                raise
        except Exception as e:
            if retry_count < max_retries and "API" in str(e):
                logger.warning(f"âš ï¸  API é”™è¯¯ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰ï¼Œé‡è¯•ä¸­...")
                import time
                time.sleep(2)
                return self.translate_batch(texts, retry_count + 1, max_retries)
            else:
                logger.error(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
                raise
    
    def extract_json(self, content: str) -> str:
        """ä»å“åº”ä¸­æå– JSONï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
        import re
        
        # 1. å°è¯•ç›´æ¥è§£æ
        if content.startswith('{') and content.endswith('}'):
            return content
        
        # 2. ç§»é™¤ä»£ç å—æ ‡è®°
        if '```' in content:
            parts = content.split('```')
            for part in parts:
                part = part.strip()
                if part.startswith('json'):
                    part = part[4:].strip()
                if part.startswith('{') and part.endswith('}'):
                    return part
        
        # 3. æ­£åˆ™æå– JSON å¯¹è±¡
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(json_pattern, content, re.DOTALL)
        if matches:
            # è¿”å›æœ€é•¿çš„åŒ¹é…ï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„ JSONï¼‰
            return max(matches, key=len)
        
        return None
    
    def has_chinese(self, text: str) -> bool:
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        import re
        return bool(re.search(r'[\u4e00-\u9fff]', text))
    
    def translate_vtt_super_smart(
        self,
        input_path: str,
        output_path: str = None,
        target_batch_size: int = 50,
        min_batch_size: int = 30,
        max_batch_size: int = 70,
        progress_dir: str = None,
        resume: bool = True
    ) -> str:
        """
        è¶…æ™ºèƒ½ç¿»è¯‘å­—å¹•ï¼ˆæ”¯æŒ VTT å’Œ SRT æ ¼å¼ï¼‰
        
        Args:
            input_path: è¾“å…¥å­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆVTT æˆ– SRTï¼‰
            output_path: è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆè‡ªåŠ¨åŒ¹é…æ ¼å¼ï¼‰
            target_batch_size: ç›®æ ‡æ‰¹æ¬¡å¤§å°
            min_batch_size: æœ€å°æ‰¹æ¬¡å¤§å°
            max_batch_size: æœ€å¤§æ‰¹æ¬¡å¤§å°
            progress_dir: è¿›åº¦æ–‡ä»¶ä¿å­˜ç›®å½•
            resume: æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # æ£€æµ‹è¾“å…¥æ ¼å¼
        input_format = detect_format(input_path)
        logger.info(f"ğŸ“‹ æ£€æµ‹åˆ°æ ¼å¼: {input_format.upper()}")
        
        # é»˜è®¤è¾“å‡ºè·¯å¾„
        if not output_path:
            input_file = Path(input_path)
            # æ ¹æ®æ ¼å¼å’Œå‘½åç”Ÿæˆè¾“å‡ºè·¯å¾„
            if input_format == 'vtt':
                if '.en.vtt' in input_file.name:
                    output_name = input_file.name.replace('.en.vtt', '.zh.vtt')
                else:
                    output_name = input_file.stem + '_zh.vtt'
            else:  # srt
                if '.en.srt' in input_file.name:
                    output_name = input_file.name.replace('.en.srt', '.zh.srt')
                else:
                    output_name = input_file.stem + '_zh.srt'
            output_path = input_file.parent / output_name
        
        # è¿›åº¦æ–‡ä»¶è·¯å¾„
        if not progress_dir:
            progress_dir = Path(input_path).parent / '.translation_progress'
        os.makedirs(progress_dir, exist_ok=True)
        
        progress_file = Path(progress_dir) / f"{Path(input_path).stem}_smart_progress.json"
        
        logger.info("="*60)
        logger.info("ğŸš€ è¶…æ™ºèƒ½å­—å¹•ç¿»è¯‘å™¨ï¼ˆæ”¯æŒ VTT/SRTï¼‰")
        logger.info("="*60)
        logger.info(f"ğŸ“ è¾“å…¥: {input_path}")
        logger.info(f"ğŸ“ è¾“å‡º: {output_path}")
        logger.info(f"ğŸ’¾ è¿›åº¦: {progress_file}")
        logger.info("")
        
        # å°è¯•åŠ è½½è¿›åº¦
        blocks = None
        start_batch = 0
        batches = None
        
        if resume:
            blocks, start_batch, batches = self.load_progress(progress_file)
        
        # å¦‚æœæ²¡æœ‰è¿›åº¦ï¼Œé‡æ–°è§£æå’Œåˆ†æ‰¹
        if blocks is None:
            # ä½¿ç”¨æ–°çš„è§£æå™¨ï¼Œè‡ªåŠ¨æ£€æµ‹æ ¼å¼
            _, parsed_blocks = parse_subtitle(input_path)
            blocks = [{'text': b['text'], 'start_time': b['start_time'], 'end_time': b['end_time']} 
                      for b in parsed_blocks]
            if not blocks:
                logger.error("âŒ æœªæ‰¾åˆ°å­—å¹•å†…å®¹")
                return None
            
            # æ™ºèƒ½åˆ†æ‰¹
            logger.info("")
            batches = self.create_smart_batches(
                blocks,
                target_size=target_batch_size,
                min_size=min_batch_size,
                max_size=max_batch_size
            )
        
        total_blocks = len(blocks)
        total_batches = len(batches)
        
        logger.info("")
        logger.info(f"ğŸ“Š ç¿»è¯‘ä»»åŠ¡:")
        logger.info(f"   æ€»å­—å¹•æ•°: {total_blocks}")
        logger.info(f"   æ™ºèƒ½æ‰¹æ¬¡æ•°: {total_batches}")
        logger.info(f"   æ‰¹æ¬¡å¤§å°èŒƒå›´: {min_batch_size}-{max_batch_size} (ç›®æ ‡: {target_batch_size})")
        
        if start_batch > 0:
            translated_count = sum(1 for b in blocks if b.get('translated'))
            logger.info(f"   å·²å®Œæˆ: {translated_count}/{total_blocks} ({translated_count*100//total_blocks}%)")
        
        logger.info("")
        logger.info("ğŸš€ å¼€å§‹ç¿»è¯‘...")
        logger.info("")
        
        # åˆ†æ‰¹ç¿»è¯‘
        for batch_idx in range(start_batch, total_batches):
            start_idx, end_idx = batches[batch_idx]
            batch_blocks = blocks[start_idx:end_idx]
            batch_size = end_idx - start_idx
            
            # è¿‡æ»¤å·²ç¿»è¯‘çš„
            to_translate = []
            to_translate_indices = []
            
            for i, block in enumerate(batch_blocks):
                if not block.get('translated'):
                    to_translate.append(block['text'])
                    to_translate_indices.append(start_idx + i)
            
            if not to_translate:
                logger.info(f"â­ï¸  æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} (å¤§å°: {batch_size}) å·²ç¿»è¯‘ï¼Œè·³è¿‡")
                continue
            
            logger.info(f"ğŸ¤– ç¿»è¯‘æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} (å¤§å°: {batch_size}, å¾…ç¿»è¯‘: {len(to_translate)})...")
            
            # æ˜¾ç¤ºæ‰¹æ¬¡çš„é¦–å°¾å­—å¹•ï¼ˆç”¨äºç¡®è®¤åˆ†æ®µåˆç†ï¼‰
            if to_translate:
                first_text = to_translate[0][:50] + "..." if len(to_translate[0]) > 50 else to_translate[0]
                last_text = to_translate[-1][:50] + "..." if len(to_translate[-1]) > 50 else to_translate[-1]
                logger.info(f"   é¦–æ¡: {first_text}")
                logger.info(f"   æœ«æ¡: {last_text}")
            
            try:
                # ç¿»è¯‘
                translations = self.translate_batch(to_translate)
                
                # æ›´æ–°ç¿»è¯‘ç»“æœ
                for idx, translation in zip(to_translate_indices, translations):
                    blocks[idx]['translated'] = translation
                
                # ä¿å­˜è¿›åº¦
                self.save_progress(progress_file, blocks, batch_idx + 1, batches)
                
                # æ˜¾ç¤ºè¿›åº¦
                total_translated = sum(1 for b in blocks if b.get('translated'))
                progress_percent = (total_translated * 100) // total_blocks
                
                # è¿›åº¦æ¡
                bar_length = 40
                filled = int(bar_length * progress_percent / 100)
                bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
                
                logger.info(f"   âœ… æ‰¹æ¬¡å®Œæˆ")
                logger.info(f"   ğŸ“Š æ€»è¿›åº¦: [{bar}] {progress_percent}% ({total_translated}/{total_blocks})")
                logger.info("")
                
            except Exception as e:
                logger.error(f"   âŒ æ‰¹æ¬¡ {batch_idx + 1} å¤±è´¥: {e}")
                logger.error(f"   ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä»¥ç¨åç»§ç»­")
                return None
        
        # ç”Ÿæˆæœ€ç»ˆå­—å¹•æ–‡ä»¶ï¼ˆæ ¹æ®è¾“å…¥æ ¼å¼ï¼‰
        logger.info(f"ğŸ’¾ ç”Ÿæˆæœ€ç»ˆ {input_format.upper()} æ–‡ä»¶...")
        
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        # è½¬æ¢ä¸º write_subtitle éœ€è¦çš„æ ¼å¼
        output_blocks = []
        for block in blocks:
            output_blocks.append({
                'start_time': block['start_time'],
                'end_time': block['end_time'],
                'text': block.get('translated') or block['text']
            })
        
        # ä½¿ç”¨æ–°çš„å†™å…¥å‡½æ•°ï¼Œè‡ªåŠ¨å¤„ç†æ ¼å¼
        write_subtitle(output_blocks, str(output_path), input_format)
        
        logger.info(f"âœ… {input_format.upper()} æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
        
        # æ¸…ç†è¿›åº¦æ–‡ä»¶
        if os.path.exists(progress_file):
            os.remove(progress_file)
            logger.info("ğŸ—‘ï¸  è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")
        
        logger.info("")
        logger.info("="*60)
        logger.info("âœ¨ ç¿»è¯‘å®Œæˆï¼")
        logger.info("="*60)
        logger.info(f"ğŸ“Š ç»Ÿè®¡:")
        logger.info(f"   å­—å¹•æ•°é‡: {total_blocks}")
        logger.info(f"   æ™ºèƒ½æ‰¹æ¬¡: {total_batches}")
        logger.info(f"   è¾“å‡ºæ–‡ä»¶: {output_path}")
        logger.info("="*60)
        logger.info("")
        
        return str(output_path)


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(
        description='ğŸš€ è¶…æ™ºèƒ½å­—å¹•ç¿»è¯‘å™¨ï¼ˆæ”¯æŒ VTT/SRT + æ™ºèƒ½åˆ†æ®µ + æ–­ç‚¹ç»­ä¼ ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ“– ä½¿ç”¨ç¤ºä¾‹:

  # 1. ç¿»è¯‘ VTT å­—å¹•
  export DEEPSEEK_API_KEY="your_api_key"
  python subtitle_translator_smart.py --input subtitle.en.vtt
  
  # 2. ç¿»è¯‘ SRT å­—å¹•
  python subtitle_translator_smart.py --input subtitle.en.srt

  # 3. è°ƒæ•´æ‰¹æ¬¡å¤§å°
  python subtitle_translator_smart.py \\
    --input subtitle.en.vtt \\
    --target-size 50 \\
    --min-size 30 \\
    --max-size 70

  # 3. ä¸­æ–­åç»§ç»­
  python subtitle_translator_smart.py --input subtitle.en.vtt --resume

ğŸ’¡ ç‰¹ç‚¹:
  - æ™ºèƒ½åˆ†æ®µï¼šåœ¨å¥å­ç»“æŸå¤„åˆ†æ‰¹ï¼Œä¿æŒè¿è´¯
  - åŠ¨æ€æ‰¹æ¬¡ï¼šç›®æ ‡50æ¡ï¼Œä½†ä¼šåœ¨è‡ªç„¶æ–­ç‚¹è°ƒæ•´
  - ä¸Šä¸‹æ–‡å®Œæ•´ï¼šé¿å…åœ¨å¥å­ä¸­é—´æˆªæ–­
  - æ–­ç‚¹ç»­ä¼ ï¼šæ”¯æŒä¸­æ–­æ¢å¤
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        required=True,
        help='è¾“å…¥å­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ VTT æˆ– SRT æ ¼å¼ï¼‰'
    )
    parser.add_argument(
        '--output', '-o',
        help='è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼Œæ ¼å¼ä¸è¾“å…¥ä¸€è‡´ï¼‰'
    )
    parser.add_argument(
        '--api-key',
        help='DeepSeek API Keyï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY è®¾ç½®ï¼‰'
    )
    parser.add_argument(
        '--target-size', '-t',
        type=int,
        default=50,
        help='ç›®æ ‡æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 50ï¼‰'
    )
    parser.add_argument(
        '--min-size',
        type=int,
        default=30,
        help='æœ€å°æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 30ï¼‰'
    )
    parser.add_argument(
        '--max-size',
        type=int,
        default=70,
        help='æœ€å¤§æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 70ï¼‰'
    )
    parser.add_argument(
        '--progress-dir',
        help='è¿›åº¦æ–‡ä»¶ä¿å­˜ç›®å½•'
    )
    parser.add_argument(
        '--resume', '-r',
        action='store_true',
        default=True,
        help='å¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼ˆé»˜è®¤å¯ç”¨ï¼‰'
    )
    parser.add_argument(
        '--no-resume',
        action='store_true',
        help='ç¦ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œä»å¤´å¼€å§‹ç¿»è¯‘'
    )
    
    args = parser.parse_args()
    
    if args.no_resume:
        args.resume = False
    
    try:
        if not os.path.exists(args.input):
            print(f"âŒ é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
            return 1
        
        translator = SuperSmartVTTTranslator(api_key=args.api_key)
        
        output_file = translator.translate_vtt_super_smart(
            input_path=args.input,
            output_path=args.output,
            target_batch_size=args.target_size,
            min_batch_size=args.min_size,
            max_batch_size=args.max_size,
            progress_dir=args.progress_dir,
            resume=args.resume
        )
        
        if output_file:
            return 0
        else:
            return 1
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç¿»è¯‘å·²ä¸­æ–­")
        print("ğŸ’¡ æç¤º: å†æ¬¡è¿è¡Œç›¸åŒå‘½ä»¤å¯ä»¥ç»§ç»­ç¿»è¯‘")
        return 1
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        return 1


if __name__ == '__main__':
    exit(main())

